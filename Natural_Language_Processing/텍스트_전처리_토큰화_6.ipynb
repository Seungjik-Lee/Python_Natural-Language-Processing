{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "텍스트 전처리 토큰화_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPvdfRU0YR0x1Vf7s5Iqtot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seungjik-Lee/Python_Natural-Language-Processing/blob/main/Natural_Language_Processing/%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%A0%84%EC%B2%98%EB%A6%AC_%ED%86%A0%ED%81%B0%ED%99%94_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeoRSfPvPVCE"
      },
      "source": [
        "# 정수 인코딩(Integer Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVaVN6NjPikl"
      },
      "source": [
        "## 1. 정수 인코딩(Integer Encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JTzxdNwQCtI"
      },
      "source": [
        "### 1) dictionary 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEgiDSlFPOld"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-MzSyqWQQBU"
      },
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mjDeWccWOi1",
        "outputId": "3745bda9-6667-499a-c591-4c0feb56d018"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ol1sNTvQIdu",
        "outputId": "c4e3d991-517b-4373-daac-5fd667e0b772"
      },
      "source": [
        "# 문장 토큰화\n",
        "text = sent_tokenize(text)\n",
        "print(text)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3ZIyg8yWZOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd75ff87-2a04-493d-aa38-53adb0ab77f5"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO5i1P_wQK-T",
        "outputId": "bd9529eb-76e4-40f0-e36b-7a78e93cfb0d"
      },
      "source": [
        "# 정제와 단어 토큰화\n",
        "vocab = {} # 파이썬의 dictionary 자료형\n",
        "sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for i in text:\n",
        "    sentence = word_tokenize(i) # 단어 토큰화를 수행.\n",
        "    result = []\n",
        "\n",
        "    for word in sentence: \n",
        "        word = word.lower() # 모든 단어를 소문자화하여 단어의 개수를 줄임.\n",
        "        if word not in stop_words: # 단어 토큰화 된 결과에 대해서 불용어를 제거.\n",
        "            if len(word) > 2: # 단어 길이가 2이하인 경우에 대하여 추가로 단어를 제거.\n",
        "                result.append(word)\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = 0 \n",
        "                vocab[word] += 1\n",
        "    sentences.append(result) \n",
        "print(sentences)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dei-rQ5DQgTD"
      },
      "source": [
        "동일한 단어가 대문자로 표기되었다는 이유로 서로 다른 단어로 카운트되는 일이 없도록 모든 단어를 소문자로 바꾸었음.<br>\n",
        "그리고 자연어 처리에서 크게 의미를 갖지 못하는 불용어와 길이가 짧은 단어를 제거하는 방법을 사용."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_52Q_iPyQoeL"
      },
      "source": [
        "현재 vocab에는 중복을 제거한 단어와 각 단어에 대한 빈도수가 기록되어져 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAiqf2MCQkee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "379b0921-500e-4591-feae-f8aa1c62462e"
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dya2PhxoQvn_"
      },
      "source": [
        "단어를 키(key)로, 단어에 대한 빈도수가 값(value)으로 저장되어져 있음. vocab에 단어를 입력하면 빈도수를 리턴."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGiBZkltQtQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99bc134-87a2-4c1c-a888-f30a3cfb762c"
      },
      "source": [
        "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-44r-yEQ63A"
      },
      "source": [
        "빈도수가 높은 순서대로 정렬."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsiyHHDYQ9E2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41900522-06c6-4057-ecee-402db89f5775"
      },
      "source": [
        "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O21P6nzcRBav"
      },
      "source": [
        "높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFjw5lhxRCMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcd649d-779f-4313-8b6b-8257e5b88760"
      },
      "source": [
        "word_to_index = {}\n",
        "i=0\n",
        "for (word, frequency) in vocab_sorted :\n",
        "    if frequency > 1 : # 빈도수가 적은 단어는 제외.\n",
        "        i=i+1\n",
        "        word_to_index[word] = i\n",
        "print(word_to_index)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NLjlIs7RKgj"
      },
      "source": [
        "1의 인덱스를 가진 단어가 가장 빈도수가 높은 단어. 등장 빈도가 낮은 단어는 자연어 처리에서 의미를 가지지 않을 가능성이 높기 때문에 각 단어의 빈도수를 알 경우에만 할 수 있는 전처리인 빈도수가 적은 단어를 제외."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBkqWCobRYlU"
      },
      "source": [
        "빈도수가 높은 순으로 낮은 정수가 부여되어져 있으므로 빈도수 상위 n개의 단어만 사용하고 싶다고하면 vocab에서 정수값이 1부터 n까지인 단어들만 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZIk0WLSRbEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8acd539-77e2-4a2c-f1c7-e24b4db2d438"
      },
      "source": [
        "vocab_size = 5\n",
        "words_frequency = [w for w,c in word_to_index.items() if c >= vocab_size + 1] # 인덱스가 5 초과인 단어 제거\n",
        "for w in words_frequency:\n",
        "    del word_to_index[w] # 해당 단어에 대한 인덱스 정보를 삭제\n",
        "print(word_to_index)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQI29TCCRsqP"
      },
      "source": [
        "이제 word_to_index를 사용하여 단어 토큰화가 된 상태로 저장된 sentences에 있는 각 단어를 정수로 바꾸는 작업을 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiqJPMp9RkSY"
      },
      "source": [
        "단어 집합에 존재하지 않는 단어들을 Out-Of-Vocabulary(단어 집합에 없는 단어)의 약자로 'OOV'라고 함. word_to_index에 'OOV'란 단어를 새롭게 추가하고, 단어 집합에 없는 단어들은 'OOV'의 인덱스로 인코딩."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnNegnAMRwRF"
      },
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkjfJAVsRyRs"
      },
      "source": [
        "word_to_index를 사용하여 sentences의 모든 단어들을 맵핑되는 정수로 인코딩."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqdLirQHR0RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc64f789-ea8a-4c2a-93ca-ca96562cdd1a"
      },
      "source": [
        "encoded = []\n",
        "for s in sentences:\n",
        "    temp = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            temp.append(word_to_index[w])\n",
        "        except KeyError:\n",
        "            temp.append(word_to_index['OOV'])\n",
        "    encoded.append(temp)\n",
        "print(encoded)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UW4ZlqTR3Yj"
      },
      "source": [
        "### 2) Counter 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H9hYOn6R8X2"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2z1OUv_R-ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706f4d88-b549-4996-ac10-3896b4e178a0"
      },
      "source": [
        "print(sentences)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFuMNvZYSEV7"
      },
      "source": [
        "단어 집합(vocabulary)을 만들기 위해서 sentences에서 문장의 경계인 [, ]를 제거하고 단어들을 하나의 리스트로 만듬."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap_HJpsGSHXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da4648c8-c1cd-4c3b-f13e-3a467adf3b41"
      },
      "source": [
        "words = sum(sentences, [])\n",
        "# 위 작업은 words = np.hstack(sentences)로도 수행 가능.\n",
        "print(words)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGknrXgfSK7J"
      },
      "source": [
        "Counter()의 입력으로 사용하면 중복을 제거하고 단어의 빈도수를 기록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjxkFvhFSMzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bbc93b8-0200-48fd-d6d4-66c29f928e5b"
      },
      "source": [
        "vocab = Counter(words) # 파이썬의 Counter 모듈을 이용하면 단어의 모든 빈도를 쉽게 계산할 수 있음.\n",
        "print(vocab)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArUr-8GrSaMO"
      },
      "source": [
        "단어를 키(key)로, 단어에 대한 빈도수가 값(value)으로 저장되어져 있음. vocab에 단어를 입력하면 빈도수를 리턴."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXq333t_SdMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c3f05b-bfe4-4a94-820e-853353c39c21"
      },
      "source": [
        "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxywTVL1Sfj0"
      },
      "source": [
        "most_common()는 상위 빈도수를 가진 주어진 수의 단어만을 리턴. 이를 사용하여 등장 빈도수가 높은 단어들을 원하는 개수만큼만 얻을 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXh182V2SlHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40d2f28-4033-4bb5-f7e1-d16d7a13de79"
      },
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slzl5o9SSpFP"
      },
      "source": [
        "높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlF0bWFvSrG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f6b4603-2549-4f75-d679-425c2348024b"
      },
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab :\n",
        "    i = i+1\n",
        "    word_to_index[word] = i\n",
        "print(word_to_index)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G0K_JmmSuna"
      },
      "source": [
        "### 3) NLTK의 FreqDist 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zw6v664Sx0l"
      },
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEgHP2ntS1Wu"
      },
      "source": [
        "# np.hstack으로 문장 구분을 제거하여 입력으로 사용 . ex) ['barber', 'person', 'barber', 'good' ... 중략 ...]\n",
        "vocab = FreqDist(np.hstack(sentences))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhZjsSYeS6uG"
      },
      "source": [
        "단어를 키(key)로, 단어에 대한 빈도수가 값(value)으로 저장되어져 있음. vocab에 단어를 입력하면 빈도수를 리턴."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JJ1748XS9AX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d86b34-f355-4bab-b3bb-8ea780d91816"
      },
      "source": [
        "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59uRv4XYTAKp"
      },
      "source": [
        "most_common()는 상위 빈도수를 가진 주어진 수의 단어만을 리턴. 이를 사용하여 등장 빈도수가 높은 단어들을 원하는 개수만큼만 얻을 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVqBkLXITIq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95cdadb7-06c4-49d8-c4b7-9612c7660d45"
      },
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya5Quf-MTL-5"
      },
      "source": [
        "높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZI-xcFuTOCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af73091-66b7-4e31-fa3a-fe67317d84ab"
      },
      "source": [
        "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n",
        "print(word_to_index)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVSWSyHKTSon"
      },
      "source": [
        "### 4) enumerate 이해하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD5pYaNHTZRq"
      },
      "source": [
        "enumerate()는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아 인덱스를 순차적으로 함께 리턴한다는 특징이 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMYqD1byTV0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072c0ea0-7e83-416a-9703-e7c2f040c338"
      },
      "source": [
        "test=['a', 'b', 'c', 'd', 'e']\n",
        "for index, value in enumerate(test): # 입력의 순서대로 0부터 인덱스를 부여함.\n",
        "  print(\"value : {}, index: {}\".format(value, index))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value : a, index: 0\n",
            "value : b, index: 1\n",
            "value : c, index: 2\n",
            "value : d, index: 3\n",
            "value : e, index: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0t4IOOyTeRt"
      },
      "source": [
        "위의 출력 결과는 리스트의 모든 토큰에 대해서 인덱스가 순차적으로 증가되며 부여된 것을 보여줌."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhxsdC8CTlaw"
      },
      "source": [
        "## 2. 케라스(Keras)의 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IocY7WUYTntI"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty646X8ETubB"
      },
      "source": [
        "앞서 사용한 텍스트 데이터와 동일한 데이터를 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VqArlxwTr-y"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences) # fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv6KU0s7Tyeu"
      },
      "source": [
        "fit_on_texts는 입력한 텍스트로부터 단어 빈도수가 높은 순으로 낮은 정수 인덱스를 부여. 정수 인코딩 작업이 이루어진다고 보면 됨.<br>\n",
        "각 단어에 인덱스가 어떻게 부여되었는지를 보려면, word_index를 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSRQvRxTT6pM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db24d0a-0d20-4f20-8588-71498153363f"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbs4nAVFT_5z"
      },
      "source": [
        "각 단어의 빈도수가 높은 순서대로 인덱스가 부여된 것을 확인할 수 있음. 각 단어가 카운트를 수행하였을 때 몇 개였는지를 보고자 한다면 word_counts를 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTNAApvQUB9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3182e041-a80a-4677-c5ce-b46aa4403d46"
      },
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gUA3s5uUGS7"
      },
      "source": [
        "texts_to_sequences()는 입력으로 들어온 코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi8l7xeCUIlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b70b2f-da41-4670-9230-0e95260b0394"
      },
      "source": [
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHSMZ9B4UOQc"
      },
      "source": [
        "빈도수가 가장 높은 단어 n개만을 사용하기 위해서 most_common()을 사용.<br>\n",
        "케라스 토크나이저에서는 tokenizer = Tokenizer(num_words=숫자)와 같은 방법으로 빈도수가 높은 상위 몇 개의 단어만 사용하겠다고 지정할 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poQC9ndGUU-k"
      },
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 1) # 상위 5개 단어만 사용\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVv3uF-aUZdg"
      },
      "source": [
        "num_words에서 +1을 더해서 값을 넣어주는 이유는 num_words는 숫자를 0부터 카운트.<br>\n",
        "케라스 토크나이저가 숫자 0까지 단어 집합의 크기로 산정하는 이유는 자연어 처리에서 패딩(padding)이라는 작업 때문임."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZd7GOS9Ujft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163d1945-ed37-4c3c-8374-73d468daa707"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw6BN6RLU-uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5281b1-4a1e-437e-a312-f30b59c4b9c1"
      },
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV5RPZE6VBVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed0efab7-3910-49a6-b87a-60b3d717048e"
      },
      "source": [
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR-clwrIVfgZ"
      },
      "source": [
        "코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환하는데, 상위 5개의 단어만을 사용하겠다고 지정하였으므로 1번 단어부터 5번 단어까지만 보존되고 나머지 단어들은 제거된 것을 볼 수 있음."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apVqvJpCVoUy"
      },
      "source": [
        "---word_index와 word_counts에서도 지정된 num_words만큼의 단어만 남기고 싶다면 아래의 코드도 방법----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxOXkjp7Vr0E"
      },
      "source": [
        "tokenizer = Tokenizer() # num_words를 여기서는 지정하지 않은 상태\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ciofNeVtZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd03076-6f3c-48ce-a466-903220a82a77"
      },
      "source": [
        "vocab_size = 5\n",
        "words_frequency = [w for w,c in tokenizer.word_index.items() if c >= vocab_size + 1] # 인덱스가 5 초과인 단어 제거\n",
        "for w in words_frequency:\n",
        "    del tokenizer.word_index[w] # 해당 단어에 대한 인덱스 정보를 삭제\n",
        "    del tokenizer.word_counts[w] # 해당 단어에 대한 카운트 정보를 삭제\n",
        "print(tokenizer.word_index)\n",
        "print(tokenizer.word_counts)\n",
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n",
            "OrderedDict([('barber', 8), ('person', 3), ('huge', 5), ('secret', 6), ('kept', 4)])\n",
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y7jq5etV3b2"
      },
      "source": [
        "케라스 토크나이저는 기본적으로 단어 집합에 없는 단어인 OOV에 대해서는 단어를 정수로 바꾸는 과정에서 아예 단어를 제거한다는 특징이 있음.<br>\n",
        "단어 집합에 없는 단어들은 OOV로 간주하여 보존하고 싶다면 Tokenizer의 인자 oov_token을 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MqjRydXV8_j"
      },
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
        "# 빈도수 상위 5개 단어만 사용. 숫자 0과 OOV를 고려해서 단어 집합의 크기는 +2\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiGaLFBSV_rd"
      },
      "source": [
        "만약 oov_token을 사용하기로 했다면 케라스 토크나이저는 기본적으로 'OOV'의 인덱스를 1로 함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p42Hugg3WDcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e48043-4fc0-4e07-976a-48946fd3adcf"
      },
      "source": [
        "print('단어 OOV의 인덱스 : {}'.format(tokenizer.word_index['OOV']))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AxjQ-pKWC1X"
      },
      "source": [
        "코퍼스에 대해서 정수 인코딩을 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v-xNx_fWGw-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb75b21-c28d-4b1a-8566-f74ee2ef72c3"
      },
      "source": [
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 6], [2, 1, 6], [2, 4, 6], [1, 3], [3, 5, 4, 3], [4, 3], [2, 5, 1], [2, 5, 1], [2, 5, 3], [1, 1, 4, 3, 1, 2, 1], [2, 1, 4, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}